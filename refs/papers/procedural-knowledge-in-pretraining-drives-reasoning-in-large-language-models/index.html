<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="2411.12580v1.Procedural_Knowledge_in_Pretraining_Drives_Reasoning_in_Large_Language_Models.pdf" name="source_pdf" />
<meta content="2024-11-25 20:42:59" name="summary_date" />
<meta property="og:title" content="Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models" />
<meta property="og:type" content="website" />
<meta property="og:url" content="refs/papers/procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models/" />
<meta property="og:site_name" content="geometor • arcprize" />
<meta property="og:description" content="id, 2411.12580,, Authors, Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo,, Publi..." />
<meta name="description" content="id, 2411.12580,, Authors, Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo,, Publi..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models &mdash; geometor • arcprize</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=ea5fcf70" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />

  
    <link rel="canonical" href="https://geometor.github.io/arcprize/refs/papers/procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models/" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=187304be"></script>
        <script src="../../../_static/doctools.js?v=9bcbadda"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../../about/" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus" href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/" />
    <link rel="prev" title="Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4" href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/" />   
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../log/atom.xml"
  title="geometor • arcprize"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            geometor • arcprize
              <img src="../../../_static/arcprize-logo-200.gif" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../mission/">mission</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/">usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/">modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logs/">logs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../">references</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../">papers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../a-divide-align-conquer-strategy-for-program-synthesis/">A Divide-Align-Conquer Strategy for Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../addressing-the-abstraction-and-reasoning-corpus-via-procedural-example-generation/">Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alice-in-wonderland-simple-tasks-showing-complete-reasoning-breakdown-in-state-of-the-art-large-language-models/">Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../analog-bits-generating-discrete-data-using-diffusion-models-with-self-conditioning/"><span class="sectnum">1 </span>Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../arcle-the-abstraction-and-reasoning-corpus-learning-environment-for-reinforcement-learning/">ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../attention-heads-of-large-language-models-a-survey/">Attention Heads of Large Language Models: A Survey</a></li>
<li class="toctree-l3"><a class="reference internal" href="../automated-design-of-agentic-systems/">Automated Design of Agentic Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../combining-induction-and-transduction-for-abstract-reasoning/">Combining Induction and Transduction for Abstract Reasoning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../communicating-natural-programs-to-humans-and-machines/">Communicating Natural Programs to Humans and Machines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-for-world-modeling-visual-details-matter-in-atari/">Diffusion for World Modeling: Visual Details Matter in Atari</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-on-syntax-trees-for-program-synthesis/">Diffusion On Syntax Trees For Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dreamcoder-growing-generalizable-interpretable-knowledge-with-wake-sleep-bayesian-program-learning/">DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../generative-agent-simulations-of-1000-people/">Generative Agent Simulations of 1,000 People</a></li>
<li class="toctree-l3"><a class="reference internal" href="../h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark/">H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/">Learning to (Learn at Test Time): RNNs with Expressive Hidden States</a></li>
<li class="toctree-l3"><a class="reference internal" href="../on-the-measure-of-intelligence/">On the Measure of Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone/"><span class="sectnum">1 </span>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</a></li>
<li class="toctree-l3"><a class="reference internal" href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/">Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens</a></li>
<li class="toctree-l3"><a class="reference internal" href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/">Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#abstract">abstract</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#premise">premise</a></li>
<li class="toctree-l5"><a class="reference internal" href="#outline">outline</a></li>
<li class="toctree-l5"><a class="reference internal" href="#quotes">quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notes">notes</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#summary">summary</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#brief-overview">1. Brief overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="#key-points">2. Key points</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notable-quotes">3. Notable quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#primary-themes">4. Primary themes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/">Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../relational-decomposition-for-program-synthesis/"><span class="sectnum">1 </span><span class="sectnum">1 </span>Relational decomposition for program synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../searching-latent-program-spaces/">Searching Latent Program Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tackling-the-abstraction-and-reasoning-corpus-arc-with-object-centric-models-and-the-mdl-principle/">Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../training-language-models-to-self-correct-via-reinforcement-learning/">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tree-of-problems-improving-structured-problem-solving-with-compositionality/">Tree of Problems: Improving structured problem solving with compositionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/">Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1/">When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../repos/">repos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pages/">pages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../youtube/">youtube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../todos/">todos</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">geometor • arcprize</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../">references</a></li>
          <li class="breadcrumb-item"><a href="../">papers</a></li>
      <li class="breadcrumb-item active">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/geometor/arcprize/blob/main/docsrc/refs/papers/procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/" class="btn btn-neutral float-left" title="Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/" class="btn btn-neutral float-right" title="Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
              <section id="procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models">
<span id="id1"></span><h1>Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models<a class="headerlink" href="#procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models" title="Link to this heading"></a></h1>
<dl class="field-list simple">
<dt class="field-odd">id<span class="colon">:</span></dt>
<dd class="field-odd"><p>2411.12580</p>
</dd>
<dt class="field-even">Authors<span class="colon">:</span></dt>
<dd class="field-even"><p>Laura Ruis, Maximilian Mozes, Juhan Bae, Siddhartha Rao Kamalakara, Dwarak Talupuru, Acyr Locatelli, Robert Kirk, Tim Rocktäschel, Edward Grefenstette, Max Bartolo</p>
</dd>
<dt class="field-odd">Published<span class="colon">:</span></dt>
<dd class="field-odd"><p>2024-11-19</p>
</dd>
<dt class="field-even">arXiv<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://arxiv.org/abs/2411.12580">https://arxiv.org/abs/2411.12580</a></p>
</dd>
<dt class="field-odd">PDF<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://arxiv.org/pdf/2411.12580">https://arxiv.org/pdf/2411.12580</a></p>
</dd>
<dt class="field-even">DOI<span class="colon">:</span></dt>
<dd class="field-even"><p>N/A</p>
</dd>
<dt class="field-odd">Journal Reference<span class="colon">:</span></dt>
<dd class="field-odd"><p>N/A</p>
</dd>
<dt class="field-even">Primary Category<span class="colon">:</span></dt>
<dd class="field-even"><p>cs.CL</p>
</dd>
<dt class="field-odd">Categories<span class="colon">:</span></dt>
<dd class="field-odd"><p>cs.CL, cs.LG</p>
</dd>
<dt class="field-even">Comment<span class="colon">:</span></dt>
<dd class="field-even"><p>N/A</p>
</dd>
<dt class="field-odd">github_url<span class="colon">:</span></dt>
<dd class="field-odd"><p>_</p>
</dd>
</dl>
<section id="abstract">
<h2>abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h2>
<p>The capabilities and limitations of Large Language Models have been sketched
out in great detail in recent years, providing an intriguing yet conflicting
picture. On the one hand, LLMs demonstrate a general ability to solve problems.
On the other hand, they show surprising reasoning gaps when compared to humans,
casting doubt on the robustness of their generalisation strategies. The sheer
volume of data used in the design of LLMs has precluded us from applying the
method traditionally used to measure generalisation: train-test set separation.
To overcome this, we study what kind of generalisation strategies LLMs employ
when performing reasoning tasks by investigating the pretraining data they rely
on. For two models of different sizes (7B and 35B) and 2.5B of their
pretraining tokens, we identify what documents influence the model outputs for
three simple mathematical reasoning tasks and contrast this to the data that
are influential for answering factual questions. We find that, while the models
rely on mostly distinct sets of data for each factual question, a document
often has a similar influence across different reasoning questions within the
same task, indicating the presence of procedural knowledge. We further find
that the answers to factual questions often show up in the most influential
data. However, for reasoning questions the answers usually do not show up as
highly influential, nor do the answers to the intermediate reasoning steps.
When we characterise the top ranked documents for the reasoning questions
qualitatively, we confirm that the influential documents often contain
procedural knowledge, like demonstrating how to obtain a solution using
formulae or code. Our findings indicate that the approach to reasoning the
models use is unlike retrieval, and more like a generalisable strategy that
synthesises procedural knowledge from documents doing a similar form of
reasoning.</p>
<section id="premise">
<h3>premise<a class="headerlink" href="#premise" title="Link to this heading"></a></h3>
</section>
<section id="outline">
<h3>outline<a class="headerlink" href="#outline" title="Link to this heading"></a></h3>
</section>
<section id="quotes">
<h3>quotes<a class="headerlink" href="#quotes" title="Link to this heading"></a></h3>
</section>
<section id="notes">
<h3>notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h3>
</section>
</section>
<section id="summary">
<h2>summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<section id="brief-overview">
<h3>1. Brief overview<a class="headerlink" href="#brief-overview" title="Link to this heading"></a></h3>
<p>This paper investigates how large language models (LLMs) generalize when performing reasoning tasks.  The authors overcome the limitations of traditional train-test set separation by analyzing the pretraining data that influences model outputs for various reasoning and factual questions. They focus on three simple mathematical reasoning tasks and contrast them with factual questions, using influence functions to identify influential documents.  The research is conducted on two Cohere Command R models (7B and 35B parameters) and a subset of their pretraining data.</p>
</section>
<section id="key-points">
<h3>2. Key points<a class="headerlink" href="#key-points" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Procedural knowledge drives reasoning:</strong> Documents influencing reasoning traces often contain procedural knowledge (e.g., formulas or code demonstrating solution methods).  This suggests LLMs are generalizing strategies rather than simply retrieving answers.</p></li>
<li><p><strong>Models rely less on individual documents for reasoning:</strong> The influence of individual documents on reasoning is weaker than on factual questions, indicating a reliance on a broader, more general set of documents.</p></li>
<li><p><strong>Factual answers are often found in influential data, reasoning answers rarely are:</strong> Answers to factual questions frequently appear in highly influential pretraining documents. This is not the case for reasoning questions, nor for intermediate reasoning steps.</p></li>
<li><p><strong>Code plays a significant role in mathematical reasoning:</strong> Code data is overrepresented among influential documents for reasoning tasks. This highlights the importance of high-quality procedural data in model pretraining.</p></li>
<li><p><strong>Larger models show stronger effects:</strong>  The 35B parameter model exhibited more pronounced differences in influence between reasoning and factual questions compared to the 7B parameter model.</p></li>
</ul>
</section>
<section id="notable-quotes">
<h3>3. Notable quotes<a class="headerlink" href="#notable-quotes" title="Link to this heading"></a></h3>
<p>No direct quotes were extracted as significantly important for future reference. The findings are primarily conveyed through the results and analysis.</p>
</section>
<section id="primary-themes">
<h3>4. Primary themes<a class="headerlink" href="#primary-themes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>LLM Generalization:</strong> The core theme is understanding how LLMs generalize to new reasoning tasks, moving beyond simple retrieval-based explanations.</p></li>
<li><p><strong>Interpretability:</strong> The study uses influence functions to gain insights into the internal mechanisms of LLMs, exploring what parts of the training data are most influential for specific types of questions.</p></li>
<li><p><strong>Pretraining Data Impact:</strong> A crucial theme is the role of pretraining data quality and composition in driving the success of LLMs on reasoning tasks.  The study suggests that focusing on high-quality procedural knowledge rather than comprehensive coverage of all possible cases might be a more effective approach for pretraining.</p></li>
</ul>
</section>
</section>
</section>

<div class="section">
   
</div>

           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/" class="btn btn-neutral float-left" title="Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/" class="btn btn-neutral float-right" title="Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, geometor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>