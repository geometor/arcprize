<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="2404.14219v4.Phi_3_Technical_Report__A_Highly_Capable_Language_Model_Locally_on_Your_Phone.pdf" name="source_pdf" />
<meta content="2024-11-25 20:41:28" name="summary_date" />
<meta property="og:title" content="1 Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone" />
<meta property="og:type" content="website" />
<meta property="og:url" content="refs/papers/phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone/" />
<meta property="og:site_name" content="geometor • arcprize" />
<meta property="og:description" content="1 Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone: id, 2404.14219,, Authors, Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, A..." />
<meta name="description" content="1 Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone: id, 2404.14219,, Authors, Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, A..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>1 Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone &mdash; geometor • arcprize</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=ea5fcf70" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />

  
    <link rel="canonical" href="https://geometor.github.io/arcprize/refs/papers/phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone/" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=187304be"></script>
        <script src="../../../_static/doctools.js?v=9bcbadda"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../../about/" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens" href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/" />
    <link rel="prev" title="On the Measure of Intelligence" href="../on-the-measure-of-intelligence/" />   
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../log/atom.xml"
  title="geometor • arcprize"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            geometor • arcprize
              <img src="../../../_static/arcprize-logo-200.gif" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../mission/">mission</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/">usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/">modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logs/">logs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../">references</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../">papers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../a-divide-align-conquer-strategy-for-program-synthesis/">A Divide-Align-Conquer Strategy for Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../addressing-the-abstraction-and-reasoning-corpus-via-procedural-example-generation/">Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alice-in-wonderland-simple-tasks-showing-complete-reasoning-breakdown-in-state-of-the-art-large-language-models/">Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../analog-bits-generating-discrete-data-using-diffusion-models-with-self-conditioning/"><span class="sectnum">1 </span>Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../arcle-the-abstraction-and-reasoning-corpus-learning-environment-for-reinforcement-learning/">ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../attention-heads-of-large-language-models-a-survey/">Attention Heads of Large Language Models: A Survey</a></li>
<li class="toctree-l3"><a class="reference internal" href="../automated-design-of-agentic-systems/">Automated Design of Agentic Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../combining-induction-and-transduction-for-abstract-reasoning/">Combining Induction and Transduction for Abstract Reasoning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../communicating-natural-programs-to-humans-and-machines/">Communicating Natural Programs to Humans and Machines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-for-world-modeling-visual-details-matter-in-atari/">Diffusion for World Modeling: Visual Details Matter in Atari</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-on-syntax-trees-for-program-synthesis/">Diffusion On Syntax Trees For Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dreamcoder-growing-generalizable-interpretable-knowledge-with-wake-sleep-bayesian-program-learning/">DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../generative-agent-simulations-of-1000-people/">Generative Agent Simulations of 1,000 People</a></li>
<li class="toctree-l3"><a class="reference internal" href="../h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark/">H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/">Learning to (Learn at Test Time): RNNs with Expressive Hidden States</a></li>
<li class="toctree-l3"><a class="reference internal" href="../on-the-measure-of-intelligence/">On the Measure of Intelligence</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#"><span class="sectnum">1 </span>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#abstract"><span class="sectnum">1.1 </span>abstract</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#premise">premise</a></li>
<li class="toctree-l5"><a class="reference internal" href="#outline">outline</a></li>
<li class="toctree-l5"><a class="reference internal" href="#quotes">quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notes">notes</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#summary"><span class="sectnum">1.2 </span>summary</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#brief-overview">1. Brief Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="#key-points">2. Key Points</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notable-quotes">3. Notable Quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#primary-themes">4. Primary Themes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/">Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens</a></li>
<li class="toctree-l3"><a class="reference internal" href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/">Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models/">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/">Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../relational-decomposition-for-program-synthesis/"><span class="sectnum">1 </span><span class="sectnum">1 </span>Relational decomposition for program synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../searching-latent-program-spaces/">Searching Latent Program Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tackling-the-abstraction-and-reasoning-corpus-arc-with-object-centric-models-and-the-mdl-principle/">Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../training-language-models-to-self-correct-via-reinforcement-learning/">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tree-of-problems-improving-structured-problem-solving-with-compositionality/">Tree of Problems: Improving structured problem solving with compositionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/">Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1/">When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../repos/">repos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pages/">pages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../youtube/">youtube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../todos/">todos</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">geometor • arcprize</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../">references</a></li>
          <li class="breadcrumb-item"><a href="../">papers</a></li>
      <li class="breadcrumb-item active"><span class="sectnum">1 </span>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/geometor/arcprize/blob/main/docsrc/refs/papers/phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="../on-the-measure-of-intelligence/" class="btn btn-neutral float-left" title="On the Measure of Intelligence" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/" class="btn btn-neutral float-right" title="Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
              <section id="phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone">
<span id="id1"></span><h1><span class="sectnum">1 </span>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone<a class="headerlink" href="#phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone" title="Link to this heading"></a></h1>
<dl class="field-list simple">
<dt class="field-odd">id<span class="colon">:</span></dt>
<dd class="field-odd"><p>2404.14219</p>
</dd>
<dt class="field-even">Authors<span class="colon">:</span></dt>
<dd class="field-even"><p>Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, Alon Benhaim, Misha Bilenko, Johan Bjorck, Sébastien Bubeck, Martin Cai, Qin Cai, Vishrav Chaudhary, Dong Chen, Dongdong Chen, Weizhu Chen, Yen-Chun Chen, Yi-Ling Chen, Hao Cheng, Parul Chopra, Xiyang Dai, Matthew Dixon, Ronen Eldan, Victor Fragoso, Jianfeng Gao, Mei Gao, Min Gao, Amit Garg, Allie Del Giorno, Abhishek Goswami, Suriya Gunasekar, Emman Haider, Junheng Hao, Russell J. Hewett, Wenxiang Hu, Jamie Huynh, Dan Iter, Sam Ade Jacobs, Mojan Javaheripi, Xin Jin, Nikos Karampatziakis, Piero Kauffmann, Mahoud Khademi, Dongwoo Kim, Young Jin Kim, Lev Kurilenko, James R. Lee, Yin Tat Lee, Yuanzhi Li, Yunsheng Li, Chen Liang, Lars Liden, Xihui Lin, Zeqi Lin, Ce Liu, Liyuan Liu, Mengchen Liu, Weishung Liu, Xiaodong Liu, Chong Luo, Piyush Madan, Ali Mahmoudzadeh, David Majercak, Matt Mazzola, Caio César Teodoro Mendes, Arindam Mitra, Hardik Modi, Anh Nguyen, Brandon Norick, Barun Patra, Daniel Perez-Becker, Thomas Portet, Reid Pryzant, Heyang Qin, Marko Radmilac, Liliang Ren, Gustavo de Rosa, Corby Rosset, Sambudha Roy, Olatunji Ruwase, Olli Saarikivi, Amin Saied, Adil Salim, Michael Santacroce, Shital Shah, Ning Shang, Hiteshi Sharma, Yelong Shen, Swadheen Shukla, Xia Song, Masahiro Tanaka, Andrea Tupini, Praneetha Vaddamanu, Chunyu Wang, Guanhua Wang, Lijuan Wang, Shuohang Wang, Xin Wang, Yu Wang, Rachel Ward, Wen Wen, Philipp Witte, Haiping Wu, Xiaoxia Wu, Michael Wyatt, Bin Xiao, Can Xu, Jiahang Xu, Weijian Xu, Jilong Xue, Sonali Yadav, Fan Yang, Jianwei Yang, Yifan Yang, Ziyi Yang, Donghan Yu, Lu Yuan, Chenruidong Zhang, Cyril Zhang, Jianwen Zhang, Li Lyna Zhang, Yi Zhang, Yue Zhang, Yunan Zhang, Xiren Zhou</p>
</dd>
<dt class="field-odd">Published<span class="colon">:</span></dt>
<dd class="field-odd"><p>2024-04-22</p>
</dd>
<dt class="field-even">arXiv<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://arxiv.org/abs/2404.14219">https://arxiv.org/abs/2404.14219</a></p>
</dd>
<dt class="field-odd">PDF<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://arxiv.org/pdf/2404.14219">https://arxiv.org/pdf/2404.14219</a></p>
</dd>
<dt class="field-even">DOI<span class="colon">:</span></dt>
<dd class="field-even"><p>N/A</p>
</dd>
<dt class="field-odd">Journal Reference<span class="colon">:</span></dt>
<dd class="field-odd"><p>N/A</p>
</dd>
<dt class="field-even">Primary Category<span class="colon">:</span></dt>
<dd class="field-even"><p>cs.CL</p>
</dd>
<dt class="field-odd">Categories<span class="colon">:</span></dt>
<dd class="field-odd"><p>cs.CL, cs.AI</p>
</dd>
<dt class="field-even">Comment<span class="colon">:</span></dt>
<dd class="field-even"><p>24 pages</p>
</dd>
<dt class="field-odd">github_url<span class="colon">:</span></dt>
<dd class="field-odd"><p>_</p>
</dd>
</dl>
<section id="abstract">
<h2><span class="sectnum">1.1 </span>abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h2>
<p>We introduce phi-3-mini, a 3.8 billion parameter language model trained on
3.3 trillion tokens, whose overall performance, as measured by both academic
benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and
GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite
being small enough to be deployed on a phone. Our training dataset is a
scaled-up version of the one used for phi-2, composed of heavily filtered
publicly available web data and synthetic data. The model is also further
aligned for robustness, safety, and chat format. We also provide
parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called
phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini
(e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance
multilingual, multimodal, and long-context capabilities, we introduce three
models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision.
The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters,
achieves superior performance in language reasoning, math, and code tasks
compared to other open-source models of similar scale, such as Llama 3.1 and
the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini.
Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from
phi-3.5-mini, excels in reasoning tasks and is adept at handling both
single-image and text prompts, as well as multi-image and text prompts.</p>
<section id="premise">
<h3>premise<a class="headerlink" href="#premise" title="Link to this heading"></a></h3>
</section>
<section id="outline">
<h3>outline<a class="headerlink" href="#outline" title="Link to this heading"></a></h3>
</section>
<section id="quotes">
<h3>quotes<a class="headerlink" href="#quotes" title="Link to this heading"></a></h3>
</section>
<section id="notes">
<h3>notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h3>
</section>
</section>
<section id="summary">
<h2><span class="sectnum">1.2 </span>summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<section id="brief-overview">
<h3>1. Brief Overview<a class="headerlink" href="#brief-overview" title="Link to this heading"></a></h3>
<p>This technical report introduces phi-3-mini, a 3.8 billion parameter language model capable of running locally on a phone.  Despite its small size, its performance rivals much larger models like Mixtral 8x7B and GPT-3.5, achieving comparable results on various benchmarks.  The model’s success is attributed to an advanced training dataset that combines heavily filtered public web data with synthetic data generated by LLMs. The report also details larger variants (phi-3-small, phi-3-medium) and extensions focusing on multilingual, multimodal (phi-3.5-Vision), and long-context (phi-3-mini-128k) capabilities.  A strong emphasis is placed on safety and responsible AI development.</p>
</section>
<section id="key-points">
<h3>2. Key Points<a class="headerlink" href="#key-points" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Small Size, High Performance:</strong> phi-3-mini rivals larger models in performance while being small enough for on-device deployment.</p></li>
<li><p><strong>Data-Driven Optimization:</strong>  Improved performance stems from a novel training data strategy utilizing LLM-based filtering and synthetic data.</p></li>
<li><p><strong>Multilingual and Multimodal Extensions:</strong> phi-3.5 series models enhance multilingual, multimodal, and long-context capabilities.</p></li>
<li><p><strong>Safety and Responsibility:</strong>  The models were developed with a focus on safety and responsible AI, incorporating various safety measures throughout the development process.</p></li>
<li><p><strong>Superior Performance in Certain Benchmarks:</strong>  The phi-3.5-MoE model, in particular, exhibits superior performance to other open-source models of similar size in specific tasks.</p></li>
</ul>
</section>
<section id="notable-quotes">
<h3>3. Notable Quotes<a class="headerlink" href="#notable-quotes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>“It’s like fitting a supercomputer in a flip phone, but instead of breaking the phone, it just breaks the internet with its tiny, yet mighty, linguistic prowess!” (Informal description of the model’s surprising capabilities).</p></li>
<li><p>“The development of a compact language model that rivals the capabilities of ChatGPT, while fitting on a phone, is a testament to the power of data-driven machine learning.” (Serious description of model capabilities).</p></li>
</ul>
</section>
<section id="primary-themes">
<h3>4. Primary Themes<a class="headerlink" href="#primary-themes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Scaling Laws Redefined:</strong> The paper challenges the traditional scaling laws of LLMs by demonstrating that data quality can significantly impact performance more than model size.</p></li>
<li><p><strong>Efficient Model Design:</strong>  Focus on creating efficient models that can run on resource-constrained devices, like smartphones.</p></li>
<li><p><strong>Responsible AI:</strong>  A significant portion of the report emphasizes the importance of safety and responsible AI practices throughout model development and deployment.</p></li>
<li><p><strong>Benchmarking and Comparison:</strong> Comprehensive benchmarking against various state-of-the-art models across multiple tasks.</p></li>
</ul>
</section>
</section>
</section>

<div class="section">
   
</div>

           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../on-the-measure-of-intelligence/" class="btn btn-neutral float-left" title="On the Measure of Intelligence" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/" class="btn btn-neutral float-right" title="Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, geometor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>