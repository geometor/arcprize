<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="2410.01792v2.When_a_language_model_is_optimized_for_reasoning__does_it_still_show_embers_of_autoregression__An_analysis_of_OpenAI_o1.pdf" name="source_pdf" />
<meta content="2024-11-25 20:39:49" name="summary_date" />
<meta property="og:title" content="When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1" />
<meta property="og:type" content="website" />
<meta property="og:url" content="refs/papers/when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1/" />
<meta property="og:site_name" content="geometor • arcprize" />
<meta property="og:description" content="id, 2410.01792,, Authors,- Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths.,, Published, 2024-10-02,, arXiv, https://arxiv.org/abs/2410.01792,, PDF, https://arxiv.org/p..." />
<meta name="description" content="id, 2410.01792,, Authors,- Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths.,, Published, 2024-10-02,, arXiv, https://arxiv.org/abs/2410.01792,, PDF, https://arxiv.org/p..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1 &mdash; geometor • arcprize</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=f2e8749c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />

  
    <link rel="canonical" href="https://geometor.github.io/arcprize/refs/papers/when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1/" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=187304be"></script>
        <script src="../../../_static/doctools.js?v=9bcbadda"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../../about/" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="repos" href="../../repos/" />
    <link rel="prev" title="Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer" href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/" />   
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../log/atom.xml"
  title="geometor • arcprize"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            geometor • arcprize
              <img src="../../../_static/arcprize-logo-200.gif" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../mission/">mission</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/">usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/">modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logs/">logs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../">references</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../">papers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../a-divide-align-conquer-strategy-for-program-synthesis/">A Divide-Align-Conquer Strategy for Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../addressing-the-abstraction-and-reasoning-corpus-via-procedural-example-generation/">Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alice-in-wonderland-simple-tasks-showing-complete-reasoning-breakdown-in-state-of-the-art-large-language-models/">Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../analog-bits-generating-discrete-data-using-diffusion-models-with-self-conditioning/"><span class="sectnum">1 </span>Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../arcle-the-abstraction-and-reasoning-corpus-learning-environment-for-reinforcement-learning/">ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../attention-heads-of-large-language-models-a-survey/">Attention Heads of Large Language Models: A Survey</a></li>
<li class="toctree-l3"><a class="reference internal" href="../automated-design-of-agentic-systems/">Automated Design of Agentic Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../combining-induction-and-transduction-for-abstract-reasoning/">Combining Induction and Transduction for Abstract Reasoning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../communicating-natural-programs-to-humans-and-machines/">Communicating Natural Programs to Humans and Machines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-for-world-modeling-visual-details-matter-in-atari/">Diffusion for World Modeling: Visual Details Matter in Atari</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-on-syntax-trees-for-program-synthesis/">Diffusion On Syntax Trees For Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dreamcoder-growing-generalizable-interpretable-knowledge-with-wake-sleep-bayesian-program-learning/">DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../generative-agent-simulations-of-1000-people/">Generative Agent Simulations of 1,000 People</a></li>
<li class="toctree-l3"><a class="reference internal" href="../h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark/">H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark</a></li>
<li class="toctree-l3"><a class="reference internal" href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/">Learning to (Learn at Test Time): RNNs with Expressive Hidden States</a></li>
<li class="toctree-l3"><a class="reference internal" href="../on-the-measure-of-intelligence/">On the Measure of Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone/"><span class="sectnum">1 </span>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</a></li>
<li class="toctree-l3"><a class="reference internal" href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/">Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens</a></li>
<li class="toctree-l3"><a class="reference internal" href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/">Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models/">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/">Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../relational-decomposition-for-program-synthesis/"><span class="sectnum">1 </span><span class="sectnum">1 </span>Relational decomposition for program synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../searching-latent-program-spaces/">Searching Latent Program Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tackling-the-abstraction-and-reasoning-corpus-arc-with-object-centric-models-and-the-mdl-principle/">Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../training-language-models-to-self-correct-via-reinforcement-learning/">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tree-of-problems-improving-structured-problem-solving-with-compositionality/">Tree of Problems: Improving structured problem solving with compositionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/">Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#abstract">abstract</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#premise">premise</a></li>
<li class="toctree-l5"><a class="reference internal" href="#outline">outline</a></li>
<li class="toctree-l5"><a class="reference internal" href="#quotes">quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notes">notes</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#summary">summary</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#brief-overview">1. Brief overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="#key-points">2. Key points</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notable-quotes">3. Notable quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#primary-themes">4. Primary themes</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../repos/">repos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pages/">pages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../youtube/">youtube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../todos/">todos</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">geometor • arcprize</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../">references</a></li>
          <li class="breadcrumb-item"><a href="../">papers</a></li>
      <li class="breadcrumb-item active">When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/geometor/arcprize/blob/main/docsrc/refs/papers/when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/" class="btn btn-neutral float-left" title="Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../repos/" class="btn btn-neutral float-right" title="repos" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
              <section id="when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1">
<span id="id1"></span><h1>When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1<a class="headerlink" href="#when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1" title="Link to this heading"></a></h1>
<dl class="field-list simple">
<dt class="field-odd">id<span class="colon">:</span></dt>
<dd class="field-odd"><p>2410.01792</p>
</dd>
<dt class="field-even">Authors<span class="colon">:</span></dt>
<dd class="field-even"><ol class="upperalpha simple" start="18">
<li><p>Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, Thomas L. Griffiths</p></li>
</ol>
</dd>
<dt class="field-odd">Published<span class="colon">:</span></dt>
<dd class="field-odd"><p>2024-10-02</p>
</dd>
<dt class="field-even">arXiv<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://arxiv.org/abs/2410.01792">https://arxiv.org/abs/2410.01792</a></p>
</dd>
<dt class="field-odd">PDF<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://arxiv.org/pdf/2410.01792">https://arxiv.org/pdf/2410.01792</a></p>
</dd>
<dt class="field-even">DOI<span class="colon">:</span></dt>
<dd class="field-even"><p>N/A</p>
</dd>
<dt class="field-odd">Journal Reference<span class="colon">:</span></dt>
<dd class="field-odd"><p>N/A</p>
</dd>
<dt class="field-even">Primary Category<span class="colon">:</span></dt>
<dd class="field-even"><p>cs.CL</p>
</dd>
<dt class="field-odd">Categories<span class="colon">:</span></dt>
<dd class="field-odd"><p>cs.CL, cs.AI</p>
</dd>
<dt class="field-even">Comment<span class="colon">:</span></dt>
<dd class="field-even"><p>6 pages; updated to fix typo in Fig 4 caption</p>
</dd>
<dt class="field-odd">github_url<span class="colon">:</span></dt>
<dd class="field-odd"><p>_</p>
</dd>
</dl>
<section id="abstract">
<h2>abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h2>
<p>In “Embers of Autoregression” (McCoy et al., 2023), we showed that several
large language models (LLMs) have some important limitations that are
attributable to their origins in next-word prediction. Here we investigate
whether these issues persist with o1, a new system from OpenAI that differs
from previous LLMs in that it is optimized for reasoning. We find that o1
substantially outperforms previous LLMs in many cases, with particularly large
improvements on rare variants of common tasks (e.g., forming acronyms from the
second letter of each word in a list, rather than the first letter). Despite
these quantitative improvements, however, o1 still displays the same
qualitative trends that we observed in previous systems. Specifically, o1 –
like previous LLMs – is sensitive to the probability of examples and tasks,
performing better and requiring fewer “thinking tokens” in high-probability
settings than in low-probability ones. These results show that optimizing a
language model for reasoning can mitigate but might not fully overcome the
language model’s probability sensitivity.</p>
<section id="premise">
<h3>premise<a class="headerlink" href="#premise" title="Link to this heading"></a></h3>
</section>
<section id="outline">
<h3>outline<a class="headerlink" href="#outline" title="Link to this heading"></a></h3>
</section>
<section id="quotes">
<h3>quotes<a class="headerlink" href="#quotes" title="Link to this heading"></a></h3>
</section>
<section id="notes">
<h3>notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h3>
</section>
</section>
<section id="summary">
<h2>summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<section id="brief-overview">
<h3>1. Brief overview<a class="headerlink" href="#brief-overview" title="Link to this heading"></a></h3>
<p>This paper analyzes OpenAI’s new language model, o1, investigating whether it retains characteristics of autoregression despite being optimized for reasoning.  The authors find that while o1 significantly outperforms previous LLMs on various reasoning tasks, particularly those involving rare variants of common problems, it still exhibits sensitivity to both the probability of outputs and the frequency of tasks.  This suggests that optimizing for reasoning can mitigate but not fully eliminate the influence of the model’s autoregressive origins.</p>
</section>
<section id="key-points">
<h3>2. Key points<a class="headerlink" href="#key-points" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>o1 substantially outperforms previous LLMs on many reasoning tasks, especially rare variants.</p></li>
<li><p>Despite improvements, o1 still shows sensitivity to output probability (performing better on high-probability outputs).</p></li>
<li><p>o1 also displays sensitivity to task frequency (performing better on common task variants).</p></li>
<li><p>This sensitivity to probability and frequency is less pronounced in o1 than in previous LLMs.</p></li>
<li><p>The study uses “thinking tokens” as a measure of difficulty, corroborating accuracy-based findings.</p></li>
<li><p>More challenging task variations reveal stronger task frequency effects in o1.</p></li>
</ul>
</section>
<section id="notable-quotes">
<h3>3. Notable quotes<a class="headerlink" href="#notable-quotes" title="Link to this heading"></a></h3>
<p><em>No direct quotes were identified in the provided text that would be particularly valuable for future reference beyond the summary already provided.</em></p>
</section>
<section id="primary-themes">
<h3>4. Primary themes<a class="headerlink" href="#primary-themes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>The persistence of autoregressive biases in LLMs optimized for reasoning:</strong> Even when a language model is trained to focus on reasoning, its underlying autoregressive nature still influences its performance.</p></li>
<li><p><strong>The teleological perspective in AI analysis:</strong> Understanding the pressures that shape an AI system’s development is crucial for analyzing its strengths and limitations.</p></li>
<li><p><strong>Quantitative and qualitative analysis of LLM performance:</strong> The study employs both accuracy and token usage metrics to evaluate model performance, providing a more comprehensive understanding of its capabilities and limitations.</p></li>
<li><p><strong>The impact of task frequency and output probability on LLM performance:</strong> The study demonstrates the continued influence of data distribution on LLM performance, even in models specifically designed for reasoning tasks.</p></li>
</ul>
</section>
</section>
</section>

<div class="section">
   
</div>

           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/" class="btn btn-neutral float-left" title="Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../../repos/" class="btn btn-neutral float-right" title="repos" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, geometor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>