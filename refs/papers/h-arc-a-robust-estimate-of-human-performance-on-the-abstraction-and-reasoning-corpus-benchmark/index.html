<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />
<meta content="2409.01374v1.H_ARC__A_Robust_Estimate_of_Human_Performance_on_the_Abstraction_and_Reasoning_Corpus_Benchmark.pdf" name="source_pdf" />
<meta content="2024-11-25 20:42:03" name="summary_date" />
<meta property="og:title" content="H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark" />
<meta property="og:type" content="website" />
<meta property="og:url" content="refs/papers/h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark/" />
<meta property="og:site_name" content="geometor • arcprize" />
<meta property="og:description" content="id, 2409.01374,, Authors, Solim LeGris, Wai Keen Vong, Brenden M. Lake, Todd M. Gureckis,, Published, 2024-09-02,, arXiv, https://arxiv.org/abs/2409.01374,, PDF, https://arxiv.org/pdf/2409.01374,, ..." />
<meta name="description" content="id, 2409.01374,, Authors, Solim LeGris, Wai Keen Vong, Brenden M. Lake, Todd M. Gureckis,, Published, 2024-09-02,, arXiv, https://arxiv.org/abs/2409.01374,, PDF, https://arxiv.org/pdf/2409.01374,, ..." />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark &mdash; geometor • arcprize</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=ea5fcf70" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />

  
    <link rel="canonical" href="https://geometor.github.io/arcprize/refs/papers/h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark/" />
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=187304be"></script>
        <script src="../../../_static/doctools.js?v=9bcbadda"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../../../about/" />
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" />
    <link rel="next" title="Learning to (Learn at Test Time): RNNs with Expressive Hidden States" href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/" />
    <link rel="prev" title="Generative Agent Simulations of 1,000 People" href="../generative-agent-simulations-of-1000-people/" />   
<link
  rel="alternate"
  type="application/atom+xml"
  href="../../../log/atom.xml"
  title="geometor • arcprize"
/>
 
<style type="text/css">
  ul.ablog-archive {
    list-style: none;
    overflow: auto;
    margin-left: 0px;
  }
  ul.ablog-archive li {
    float: left;
    margin-right: 5px;
    font-size: 80%;
  }
  ul.postlist a {
    font-style: italic;
  }
  ul.postlist-style-disc {
    list-style-type: disc;
  }
  ul.postlist-style-none {
    list-style-type: none;
  }
  ul.postlist-style-circle {
    list-style-type: circle;
  }
</style>

</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../" class="icon icon-home">
            geometor • arcprize
              <img src="../../../_static/arcprize-logo-200.gif" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../mission/">mission</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../usage/">usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../modules/">modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../logs/">logs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../">references</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../">papers</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="../a-divide-align-conquer-strategy-for-program-synthesis/">A Divide-Align-Conquer Strategy for Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../addressing-the-abstraction-and-reasoning-corpus-via-procedural-example-generation/">Addressing the Abstraction and Reasoning Corpus via Procedural Example Generation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../alice-in-wonderland-simple-tasks-showing-complete-reasoning-breakdown-in-state-of-the-art-large-language-models/">Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../analog-bits-generating-discrete-data-using-diffusion-models-with-self-conditioning/"><span class="sectnum">1 </span>Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../arcle-the-abstraction-and-reasoning-corpus-learning-environment-for-reinforcement-learning/">ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../attention-heads-of-large-language-models-a-survey/">Attention Heads of Large Language Models: A Survey</a></li>
<li class="toctree-l3"><a class="reference internal" href="../automated-design-of-agentic-systems/">Automated Design of Agentic Systems</a></li>
<li class="toctree-l3"><a class="reference internal" href="../combining-induction-and-transduction-for-abstract-reasoning/">Combining Induction and Transduction for Abstract Reasoning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../communicating-natural-programs-to-humans-and-machines/">Communicating Natural Programs to Humans and Machines</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-for-world-modeling-visual-details-matter-in-atari/">Diffusion for World Modeling: Visual Details Matter in Atari</a></li>
<li class="toctree-l3"><a class="reference internal" href="../diffusion-on-syntax-trees-for-program-synthesis/">Diffusion On Syntax Trees For Program Synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../dreamcoder-growing-generalizable-interpretable-knowledge-with-wake-sleep-bayesian-program-learning/">DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep Bayesian program learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../florence-2-advancing-a-unified-representation-for-a-variety-of-vision-tasks/">Florence-2: Advancing a Unified Representation for a Variety of Vision Tasks</a></li>
<li class="toctree-l3"><a class="reference internal" href="../generative-agent-simulations-of-1000-people/">Generative Agent Simulations of 1,000 People</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#abstract">abstract</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#premise">premise</a></li>
<li class="toctree-l5"><a class="reference internal" href="#outline">outline</a></li>
<li class="toctree-l5"><a class="reference internal" href="#quotes">quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notes">notes</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#summary">summary</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#brief-overview">1. Brief Overview</a></li>
<li class="toctree-l5"><a class="reference internal" href="#key-points">2. Key Points</a></li>
<li class="toctree-l5"><a class="reference internal" href="#notable-quotes">3. Notable Quotes</a></li>
<li class="toctree-l5"><a class="reference internal" href="#primary-themes">4. Primary Themes</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/">Learning to (Learn at Test Time): RNNs with Expressive Hidden States</a></li>
<li class="toctree-l3"><a class="reference internal" href="../on-the-measure-of-intelligence/">On the Measure of Intelligence</a></li>
<li class="toctree-l3"><a class="reference internal" href="../phi-3-technical-report-a-highly-capable-language-model-locally-on-your-phone/"><span class="sectnum">1 </span>Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone</a></li>
<li class="toctree-l3"><a class="reference internal" href="../planning-transformer-long-horizon-offline-reinforcement-learning-with-planning-tokens/">Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens</a></li>
<li class="toctree-l3"><a class="reference internal" href="../principled-instructions-are-all-you-need-for-questioning-llama-1-2-gpt-3-5-4/">Principled Instructions Are All You Need for Questioning LLaMA-1/2, GPT-3.5/4</a></li>
<li class="toctree-l3"><a class="reference internal" href="../procedural-knowledge-in-pretraining-drives-reasoning-in-large-language-models/">Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../reasoning-abilities-of-large-language-models-in-depth-analysis-on-the-abstraction-and-reasoning-corpus/">Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus</a></li>
<li class="toctree-l3"><a class="reference internal" href="../relational-decomposition-for-program-synthesis/"><span class="sectnum">1 </span><span class="sectnum">1 </span>Relational decomposition for program synthesis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../searching-latent-program-spaces/">Searching Latent Program Spaces</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tackling-the-abstraction-and-reasoning-corpus-arc-with-object-centric-models-and-the-mdl-principle/">Tackling the Abstraction and Reasoning Corpus (ARC) with Object-centric Models and the MDL Principle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../training-language-models-to-self-correct-via-reinforcement-learning/">Training Language Models to Self-Correct via Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../tree-of-problems-improving-structured-problem-solving-with-compositionality/">Tree of Problems: Improving structured problem solving with compositionality</a></li>
<li class="toctree-l3"><a class="reference internal" href="../unraveling-the-arc-puzzle-mimicking-human-solutions-with-object-centric-decision-transformer/">Unraveling the ARC Puzzle: Mimicking Human Solutions with Object-Centric Decision Transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../when-a-language-model-is-optimized-for-reasoning-does-it-still-show-embers-of-autoregression-an-analysis-of-openai-o1/">When a language model is optimized for reasoning, does it still show embers of autoregression? An analysis of OpenAI o1</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../repos/">repos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../pages/">pages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../youtube/">youtube</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../todos/">todos</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">geometor • arcprize</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../">references</a></li>
          <li class="breadcrumb-item"><a href="../">papers</a></li>
      <li class="breadcrumb-item active">H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/geometor/arcprize/blob/main/docsrc/refs/papers/h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark/index.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul><div class="rst-breadcrumbs-buttons" role="navigation" aria-label="Sequential page navigation">
        <a href="../generative-agent-simulations-of-1000-people/" class="btn btn-neutral float-left" title="Generative Agent Simulations of 1,000 People" accesskey="p"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/" class="btn btn-neutral float-right" title="Learning to (Learn at Test Time): RNNs with Expressive Hidden States" accesskey="n">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
  </div>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
              <section id="h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark">
<span id="id1"></span><h1>H-ARC: A Robust Estimate of Human Performance on the Abstraction and Reasoning Corpus Benchmark<a class="headerlink" href="#h-arc-a-robust-estimate-of-human-performance-on-the-abstraction-and-reasoning-corpus-benchmark" title="Link to this heading"></a></h1>
<dl class="field-list simple">
<dt class="field-odd">id<span class="colon">:</span></dt>
<dd class="field-odd"><p>2409.01374</p>
</dd>
<dt class="field-even">Authors<span class="colon">:</span></dt>
<dd class="field-even"><p>Solim LeGris, Wai Keen Vong, Brenden M. Lake, Todd M. Gureckis</p>
</dd>
<dt class="field-odd">Published<span class="colon">:</span></dt>
<dd class="field-odd"><p>2024-09-02</p>
</dd>
<dt class="field-even">arXiv<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference external" href="https://arxiv.org/abs/2409.01374">https://arxiv.org/abs/2409.01374</a></p>
</dd>
<dt class="field-odd">PDF<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference external" href="https://arxiv.org/pdf/2409.01374">https://arxiv.org/pdf/2409.01374</a></p>
</dd>
<dt class="field-even">DOI<span class="colon">:</span></dt>
<dd class="field-even"><p>N/A</p>
</dd>
<dt class="field-odd">Journal Reference<span class="colon">:</span></dt>
<dd class="field-odd"><p>N/A</p>
</dd>
<dt class="field-even">Primary Category<span class="colon">:</span></dt>
<dd class="field-even"><p>cs.AI</p>
</dd>
<dt class="field-odd">Categories<span class="colon">:</span></dt>
<dd class="field-odd"><p>cs.AI</p>
</dd>
<dt class="field-even">Comment<span class="colon">:</span></dt>
<dd class="field-even"><p>12 pages, 7 figures</p>
</dd>
<dt class="field-odd">github_url<span class="colon">:</span></dt>
<dd class="field-odd"><p>_</p>
</dd>
</dl>
<section id="abstract">
<h2>abstract<a class="headerlink" href="#abstract" title="Link to this heading"></a></h2>
<p>The Abstraction and Reasoning Corpus (ARC) is a visual program synthesis
benchmark designed to test challenging out-of-distribution generalization in
humans and machines. Since 2019, limited progress has been observed on the
challenge using existing artificial intelligence methods. Comparing human and
machine performance is important for the validity of the benchmark. While
previous work explored how well humans can solve tasks from the ARC benchmark,
they either did so using only a subset of tasks from the original dataset, or
from variants of ARC, and therefore only provided a tentative estimate of human
performance. In this work, we obtain a more robust estimate of human
performance by evaluating 1729 humans on the full set of 400 training and 400
evaluation tasks from the original ARC problem set. We estimate that average
human performance lies between 73.3% and 77.2% correct with a reported
empirical average of 76.2% on the training set, and between 55.9% and 68.9%
correct with a reported empirical average of 64.2% on the public evaluation
set. However, we also find that 790 out of the 800 tasks were solvable by at
least one person in three attempts, suggesting that the vast majority of the
publicly available ARC tasks are in principle solvable by typical crowd-workers
recruited over the internet. Notably, while these numbers are slightly lower
than earlier estimates, human performance still greatly exceeds current
state-of-the-art approaches for solving ARC. To facilitate research on ARC, we
publicly release our dataset, called H-ARC (human-ARC), which includes all of
the submissions and action traces from human participants.</p>
<section id="premise">
<h3>premise<a class="headerlink" href="#premise" title="Link to this heading"></a></h3>
</section>
<section id="outline">
<h3>outline<a class="headerlink" href="#outline" title="Link to this heading"></a></h3>
</section>
<section id="quotes">
<h3>quotes<a class="headerlink" href="#quotes" title="Link to this heading"></a></h3>
</section>
<section id="notes">
<h3>notes<a class="headerlink" href="#notes" title="Link to this heading"></a></h3>
</section>
</section>
<section id="summary">
<h2>summary<a class="headerlink" href="#summary" title="Link to this heading"></a></h2>
<section id="brief-overview">
<h3>1. Brief Overview<a class="headerlink" href="#brief-overview" title="Link to this heading"></a></h3>
<p>This paper presents H-ARC, a dataset containing human performance data on the Abstraction and Reasoning Corpus (ARC) benchmark.  The study aimed to provide a robust estimate of human performance on ARC by evaluating 1729 humans on the full set of 800 tasks (400 training and 400 evaluation). The results show that human performance significantly exceeds current state-of-the-art AI approaches, with humans achieving 76.2% accuracy on the training set and 64.2% on the evaluation set.  The dataset is publicly released to facilitate further research.</p>
</section>
<section id="key-points">
<h3>2. Key Points<a class="headerlink" href="#key-points" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p>Evaluated 1729 humans on the full 800-task ARC dataset.</p></li>
<li><p>Estimated average human accuracy: 76.2% (training), 64.2% (evaluation).</p></li>
<li><p>Human performance significantly surpasses current state-of-the-art AI.</p></li>
<li><p>790 out of 800 tasks were solvable by at least one person in three attempts.</p></li>
<li><p>H-ARC dataset (human submissions and action traces) is publicly released.</p></li>
<li><p>Evaluation tasks found significantly harder than training tasks.</p></li>
<li><p>Analysis of human error patterns compared to AI models.</p></li>
</ul>
</section>
<section id="notable-quotes">
<h3>3. Notable Quotes<a class="headerlink" href="#notable-quotes" title="Link to this heading"></a></h3>
<p>No notable quotes were identified.</p>
</section>
<section id="primary-themes">
<h3>4. Primary Themes<a class="headerlink" href="#primary-themes" title="Link to this heading"></a></h3>
<ul class="simple">
<li><p><strong>Benchmarking Human Performance:</strong> The study’s primary focus is establishing a reliable benchmark for human performance on a complex reasoning task.</p></li>
<li><p><strong>Human-AI Comparison:</strong>  The results highlight the significant gap between human and AI performance on ARC.</p></li>
<li><p><strong>Dataset Release:</strong> Making the H-ARC dataset publicly available promotes further research and development in AI.</p></li>
<li><p><strong>Error Analysis:</strong>  Comparing human and AI error patterns provides insight into the differences in problem-solving approaches.</p></li>
<li><p><strong>Cognitive Science Implications:</strong>  The data offers valuable insights into human problem-solving strategies.</p></li>
</ul>
</section>
</section>
</section>

<div class="section">
   
</div>

           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../generative-agent-simulations-of-1000-people/" class="btn btn-neutral float-left" title="Generative Agent Simulations of 1,000 People" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../learning-to-learn-at-test-time-rnns-with-expressive-hidden-states/" class="btn btn-neutral float-right" title="Learning to (Learn at Test Time): RNNs with Expressive Hidden States" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, geometor.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>